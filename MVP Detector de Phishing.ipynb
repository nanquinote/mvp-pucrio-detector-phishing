{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtvZlcOr2Yn1"
   },
   "source": [
    "# **Introdução**\n",
    "\n",
    "Link para o Colab: https://colab.research.google.com/drive/1zIF2C62nHFAeUX311wuxmScag00rnxeT?authuser=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-XYoI0A9qo9"
   },
   "source": [
    "## **Definição do Problema:**\n",
    "\n",
    " O *phishing* é uma fraude digital em que sites falsos tentam enganar os usuários para roubar informações sensíveis. A identificação eficaz de URLs fraudulentas é crucial para prevenir roubo de identidade, perdas financeiras e danos à reputação.\n",
    "\n",
    "\n",
    "\n",
    "## **Objetivo:**\n",
    "\n",
    "O objetivo deste trabalho é criar um modelo de Machine Learning para classificar novas URLs entre legítimas e fraudulentas. Para isso, será usado o dataset [\"PhiUSIIL Phishing URL (Website)\"](https://archive.ics.uci.edu/dataset/967/phiusiil+phishing+url+dataset).\n",
    "\n",
    "## **Descrição do problema**\n",
    "\n",
    "### **Tipo de problema**\n",
    "\n",
    "Este é um problema de classificação supervisionada.\n",
    "\n",
    "\n",
    "## **Premissas e Hipóteses**\n",
    "\n",
    "#### **Premissas:**\n",
    "\n",
    "* O dataset fornecido é representativo e contém exemplos suficientes de URLs\n",
    "legítimas e fraudulentas para treinar um modelo de aprendizado de máquina.\n",
    "\n",
    "* As características extraídas das URLs são relevantes para o problema de classificação.\n",
    "\n",
    "#### **Hipóteses:**\n",
    "\n",
    "* As URLs fraudulentas (phishing) têm padrões específicos e características estruturais (como domínios suspeitos, presença de palavras-chave, comprimento da URL, uso de subdomínios e a presença de HTTPS) que podem ser capturados por modelos de aprendizado de máquina.\n",
    "\n",
    "* A utilização de algoritmos de aprendizado supervisionado (como regressão logística, árvores de decisão ou redes neurais) será eficaz para classificar as URLs corretamente.\n",
    "\n",
    "\n",
    "## **Restrições e Condições**\n",
    "\n",
    "* O modelo depende exclusivamente das informações contidas no dataset \"PhiUSIIL Phishing URL (Website)\". Caso o dataset seja incompleto, desatualizado ou contenha viés, o desempenho e a generalização do modelo podem ser afetados.\n",
    "\n",
    "* O modelo deve ser avaliado quanto à sua capacidade de generalizar para URLs coletadas fora do dataset original, especialmente considerando que os padrões de phishing podem evoluir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGeyFY1DDVjv"
   },
   "source": [
    "## **Dicionário de Dados**\n",
    "\n",
    "| Coluna                  | Descrição |\n",
    "|-------------------------|-----------|\n",
    "| **FILENAME**            | Nome do arquivo de origem dos dados ou nome da página analisada. |\n",
    "| **URL**                 | URL completa da página sendo analisada. |\n",
    "| **URLLength**           | Comprimento total da URL, representando o número de caracteres.|\n",
    "| **Domain**              | Nome do domínio principal da URL. |\n",
    "| **DomainLength**        | Comprimento do domínio principal.|\n",
    "| **IsDomainIP**          | Indicador binário (0 ou 1) que mostra se o domínio é um endereço IP em vez de um nome de domínio. |\n",
    "| **TLD**                 | Domínio de topo (Top-Level Domain) da URL, como .com, .org, .net, etc. |\n",
    "| **URLSimilarityIndex**  | Índice que mede a similaridade da URL com URLs legítimas, usado para identificar sites suspeitos. |\n",
    "| **CharContinuationRate**| Taxa de continuação de caracteres na URL, indicando a presença de padrões complexos ou incomuns. |\n",
    "| **TLDLegitimateProb**   | Probabilidade do TLD (domínio de topo) ser legítimo, baseada em dados históricos ou estatísticas. |\n",
    "| **URLCharProb**         | Probabilidade dos caracteres presentes na URL serem comuns em URLs legítimas. |\n",
    "| **TLDLength**           | Comprimento do domínio de topo (TLD). |\n",
    "| **NoOfSubDomain**       | Número de subdomínios presentes na URL.|\n",
    "| **HasObfuscation**      | Indicador binário (0 ou 1) que mostra se a URL possui técnicas de ofuscação para ocultar o destino real. |\n",
    "| **NoOfObfuscatedChar**  | Número de caracteres ofuscados na URL, que podem dificultar a leitura humana e indicar fraude. |\n",
    "| **ObfuscationRatio**    | Proporção de caracteres ofuscados em relação ao comprimento total da URL. |\n",
    "| **NoOfLettersInURL**    | Número total de letras presentes na URL. |\n",
    "| **LetterRatioInURL**    | Proporção de letras em relação ao comprimento total da URL. |\n",
    "| **NoOfDegitsInURL**     | Número de dígitos na URL, que podem ser usados para ocultar informações ou confundir o usuário. |\n",
    "| **DegitRatioInURL**     | Proporção de dígitos na URL em relação ao seu comprimento total. |\n",
    "| **NoOfEqualsInURL**     | Número de sinais de igual (‘=’) presentes na URL, usados em parâmetros e potencialmente indicadores de phishing. |\n",
    "| **NoOfQMarkInURL**      | Número de sinais de interrogação (‘?’) na URL, geralmente indicando o início de uma sequência de parâmetros. |\n",
    "| **NoOfAmpersandInURL**  | Número de sinais de ampersand (‘&’) presentes na URL, usados em parâmetros de consultas. |\n",
    "| **NoOfOtherSpecialCharsInURL** | Número de outros caracteres especiais na URL, que podem ser usados para enganar ou confundir o usuário. |\n",
    "| **SpacialCharRatioInURL** | Proporção de caracteres especiais em relação ao comprimento total da URL. |\n",
    "| **IsHTTPS**             | Indicador binário (0 ou 1) que mostra se a URL usa HTTPS, o que é um sinal positivo de segurança. |\n",
    "| **LineOfCode**          | Número total de linhas de código na página, uma métrica geral de complexidade. |\n",
    "| **LargestLineLength**   | Comprimento da maior linha de código, que pode indicar a presença de scripts complexos ou ofuscados. |\n",
    "| **HasTitle**            | Indicador binário (0 ou 1) de se a página possui uma tag de título, comum em sites legítimos. |\n",
    "| **Title**               | Título da página extraído da tag de título. |\n",
    "| **DomainTitleMatchScore** | Índice de correspondência entre o domínio e o título da página, podendo indicar se o site está de acordo com o nome do domínio. |\n",
    "| **URLTitleMatchScore**  | Índice de correspondência entre a URL e o título da página. |\n",
    "| **HasFavicon**          | Indicador binário (0 ou 1) de se a página possui um favicon, um sinal comum de legitimidade. |\n",
    "| **Robots**              | Indicador binário (0 ou 1) da presença de um arquivo `robots.txt`, que regula o comportamento de motores de busca. |\n",
    "| **IsResponsive**        | Indicador binário (0 ou 1) de se a página é responsiva para dispositivos móveis, comum em sites profissionais. |\n",
    "| **NoOfURLRedirect**     | Número de redirecionamentos de URL que a página faz, uma técnica usada em sites fraudulentos para esconder o destino real. |\n",
    "| **NoOfSelfRedirect**    | Número de redirecionamentos internos para o mesmo domínio. |\n",
    "| **HasDescription**      | Indicador binário (0 ou 1) de se a página possui uma meta tag de descrição, o que é comum em sites legítimos. |\n",
    "| **NoOfPopup**           | Número de pop-ups presentes, que podem indicar práticas de spam ou phishing. |\n",
    "| **NoOfiFrame**          | Número de `iframes` embutidos, que podem ser usados para conteúdo externo ou malicioso. |\n",
    "| **HasExternalFormSubmit** | Indicador binário (0 ou 1) de se o formulário da página envia dados para outro domínio, uma prática potencialmente suspeita. |\n",
    "| **HasSocialNet**        | Indicador binário (0 ou 1) de se a página possui links para redes sociais, comum em sites legítimos. |\n",
    "| **HasSubmitButton**     | Indicador binário (0 ou 1) de se a página possui um botão de envio, presente em sites com formulários. |\n",
    "| **HasHiddenFields**     | Indicador binário (0 ou 1) de se a página possui campos ocultos em formulários, que podem ser usados para coletar dados sem o conhecimento do usuário. |\n",
    "| **HasPasswordField**    | Indicador binário (0 ou 1) de se a página possui um campo de senha, indicando um possível login. |\n",
    "| **Bank**                | Indicador binário (0 ou 1) de se a página está relacionada a serviços bancários. |\n",
    "| **Pay**                 | Indicador binário (0 ou 1) de se a página oferece opções de pagamento. |\n",
    "| **Crypto**              | Indicador binário (0 ou 1) de se a página está relacionada a serviços de criptomoedas. |\n",
    "| **HasCopyrightInfo**    | Indicador binário (0 ou 1) de se a página contém informações de direitos autorais, geralmente um sinal de legitimidade. |\n",
    "| **NoOfImage**           | Número de imagens na página, uma métrica de conteúdo visual. |\n",
    "| **NoOfCSS**             | Número de folhas de estilo CSS usadas, indicando nível de personalização. |\n",
    "| **NoOfJS**              | Número de arquivos JavaScript, indicando complexidade do site. |\n",
    "| **NoOfSelfRef**         | Número de referências a URLs internas do mesmo domínio. |\n",
    "| **NoOfEmptyRef**        | Número de referências vazias (como `href=\"#\"`), que podem ser um sinal de placeholders ou práticas suspeitas. |\n",
    "| **NoOfExternalRef**     | Número de referências a URLs externas, o que pode indicar conteúdo misto. |\n",
    "| **label**               | Rótulo da classe (legítima ou fraudulenta), indicando se a página é considerada segura ou maliciosa (sendo 1 - legítimo e 0 - phishing). |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oU3l5jk0-k20"
   },
   "source": [
    "# Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLZVIGu22kg5"
   },
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1734058628000,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "jpsjbmFY_A6V"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px # para o boxplot\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler #, FunctionTransformer, RobustScaler\n",
    "#from scipy.stats.mstats import winsorize\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score, RandomizedSearchCV, learning_curve\n",
    "from sklearn.metrics import make_scorer, classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc\n",
    "from scipy.stats import randint\n",
    "#import math\n",
    "#from ydata_profiling import ProfileReport\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNtTaLcbD8B5"
   },
   "source": [
    "## Carregando o dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1607,
     "status": "ok",
     "timestamp": 1734058630915,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "VH3v-8I6XEAg"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/nanquinote/mvp-pucrio-detector-phishing/refs/heads/main/PhiUSIIL_Phishing_URL_Dataset.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzHxXZ7TnNAO"
   },
   "source": [
    "## Análise exploratória dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peKniCH7yl9s"
   },
   "source": [
    "### Visão geral e estatísticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmpXGWsfDvC5"
   },
   "source": [
    "Podemos verificar abaixo que o dataset não possui dados faltantes e que existem variáveis categóricas que precisam ser analisadas, já que não poderão ser usadas na previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1734058631831,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "MBDnDOoYDSd0",
    "outputId": "f5a2f9dc-519e-4a15-aa5f-42f1c17248aa"
   },
   "outputs": [],
   "source": [
    "display(df.head(5))\n",
    "display(df.info())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyiB-a1Xr76J"
   },
   "source": [
    "### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeN1GZ26ICSF"
   },
   "source": [
    "#### Registros Duplicados\n",
    "\n",
    "\n",
    "A seguir, é importante verificar se existem dados duplicados no dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734058631831,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "cNuo2rssINVG",
    "outputId": "a4805a09-31a9-44d6-bb1f-7b0aca2fac3f"
   },
   "outputs": [],
   "source": [
    "print(f'Registros duplicados: { df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "executionInfo": {
     "elapsed": 958,
     "status": "ok",
     "timestamp": 1734058632786,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "3FgVf7maHoI3",
    "outputId": "18b88026-5c27-4fc2-9f12-d6f7bfee28db"
   },
   "outputs": [],
   "source": [
    "duplicadas = df[df.duplicated(keep=False)]\n",
    "\n",
    "frequencia = duplicadas.value_counts()\n",
    "\n",
    "display(duplicadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "um6gdtgC3TiT"
   },
   "source": [
    "Para evitar viés no modelo, os dados duplicados serão removidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 929,
     "status": "ok",
     "timestamp": 1734058633713,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "8G6SCXpW1QyI",
    "outputId": "5d7aa21e-7f29-42a6-aa3e-3196a7476eb2"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df.duplicated().sum()\n",
    "\n",
    "print(f'Registros duplicados (após drop): { df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8K6xL4QarwRd"
   },
   "source": [
    "### Análise das colunas categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P5C3qnSrBlK"
   },
   "source": [
    "Ao analisar as colunas categóricas, podemos verificar que possuem poucos valores únicos, o que pode dificuldar a modelagem sem agregar valor. Sendo assim, optei por dropar essas colunas. O TLD até poderia fornecer informações úteis, porém como no dataset já existem as colunas TLDLegitimateProb e TLDLength não vi necessidade de mantê-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1262,
     "status": "ok",
     "timestamp": 1734058634971,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "OEQOXLN3EooA",
    "outputId": "0884294d-cdb9-4898-fc75-793f3627d953"
   },
   "outputs": [],
   "source": [
    "# Análise das colunas categóricas\n",
    "categoricas = df.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "print(f'Lista das {len(categoricas)} colunas categóricas: { categoricas }')\n",
    "\n",
    "for c in categoricas:\n",
    "  print(f'\\n{c}:\\nQtd.: {df[c].size} - Únicos: {df[c].nunique()} - Dif.: {df[c].size - df[c].nunique()}\\n')\n",
    "\n",
    "# frequência\n",
    "for c in categoricas:\n",
    "  print(df[c].value_counts().head(2), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734058634971,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "l03L4jo1FPm-"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['FILENAME', 'URL', 'Domain', 'Title', 'TLD'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpULNz9Q3pqj"
   },
   "source": [
    "### Verificando o balanceamento do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyZ9xgRu9BwI"
   },
   "source": [
    "A seguir, será verificado o balanceamento da classe target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1734058634971,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "EGRDwC7q_nQx",
    "outputId": "93dac0c5-38e1-47a3-cc2a-6c47eeeae082"
   },
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1734058635587,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "V4nIfn1f3xym",
    "outputId": "96335dba-df30-468d-edb1-f33f384f73f9"
   },
   "outputs": [],
   "source": [
    "legitimo = df['label'].value_counts()[1] / df['label'].size * 100\n",
    "phishing = df['label'].value_counts()[0] / df['label'].size * 100\n",
    "\n",
    "print(f'Legítimo: {legitimo:.2f}%')\n",
    "print(f'Phishing: {phishing:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9TkYX31tb4w"
   },
   "source": [
    "Podemos verificar que o dataset apresenta um leve desbalanceamento, o que será tratado mais adiante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNGz9lvu90nb"
   },
   "source": [
    "### Análise de outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuEfGoShARgm"
   },
   "source": [
    "Em seguida, usarei boxplot para verificar se há discrepâncias entre as features quantitativas não booleanas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1734058635588,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "hLrIzDLLAlX5"
   },
   "outputs": [],
   "source": [
    "def get_continuous_columns(df):\n",
    "    non_booleans = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        tmp = df[col].unique()\n",
    "        if not set(tmp).issubset({0, 1}):\n",
    "            non_booleans.append(col)\n",
    "\n",
    "    return non_booleans\n",
    "\n",
    "continuous_columns = get_continuous_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734058635588,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "6jWVBzTYvoAo",
    "outputId": "9e69b460-e52a-42b2-e973-3a57939ef4da"
   },
   "outputs": [],
   "source": [
    "df_continuous = df[continuous_columns]\n",
    "\n",
    "df_continuous.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1Ufu1slWerlUGsYCj-IpAjsGnBugT1HsD"
    },
    "executionInfo": {
     "elapsed": 28539,
     "status": "ok",
     "timestamp": 1734058664123,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "yG6Y-t-CDWBQ",
    "outputId": "4c08b8e2-228a-4892-ff43-775b4e3a6f77"
   },
   "outputs": [],
   "source": [
    "for col in df_continuous.columns:\n",
    "  boxplot = px.box(df_continuous, y=col)\n",
    "  boxplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6982w81B9kPT"
   },
   "source": [
    "Verificando a distribuição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1X0ypEok3ljTUmh1v4knGe3qGZgjY96si"
    },
    "executionInfo": {
     "elapsed": 36092,
     "status": "ok",
     "timestamp": 1734058700200,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "H5n8a3P58VsS",
    "outputId": "de7749a6-e08b-4e82-a931-b4ddba1558a6"
   },
   "outputs": [],
   "source": [
    "print('\\nHistogramas\\n')\n",
    "for col in df_continuous.columns:\n",
    "  histogram = px.histogram(df_continuous, x=col, y=col)\n",
    "  histogram.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1734058700200,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "X1bAG1mj9o1B",
    "outputId": "5e5dd481-5d92-458c-9454-cf79e99bd0bb"
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "  skewness = df[col].skew()\n",
    "  print(f\"Skewness {col}: {skewness}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQaoKzX4Dh_Y"
   },
   "source": [
    "Podemos verificar que existem sim outiers e features com  distribuição assimétrica, porém estes casos podem\n",
    "revelar padrões e táticas  usadas em URLs de phishing que não seriam capturados se os excluíssemos. A princípio, não pude determinar se esses dados são ruídos e erros de medição. Testei alguns tratamentos como transformação logarítimica e winsorização, porém houve uma piora significativa nas curvas de aprendizado ao aplicar essas técnicas. Sendo assim, optei por manter o modelo com todos os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SeuAVKM-VOm"
   },
   "source": [
    "A seguir, será gerado o mapa de calor para verificar inicialmente as correlações entre as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1734058700200,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "sTvVv0EwLRac",
    "outputId": "68ed8b6d-f060-4b39-ffe6-3714b3563fe8"
   },
   "outputs": [],
   "source": [
    "# Correlação e mapa de calor\n",
    "\n",
    "def gera_heatmap(df, target, k):\n",
    "  numcols = df.columns.tolist()\n",
    "  cols = df.corr().nlargest(k, target)[target].index\n",
    "  cm = df[cols].corr()\n",
    "  plt.figure(figsize=(12,6))\n",
    "  sns.heatmap(cm, annot=True, cmap = 'viridis')\n",
    "\n",
    "gera_heatmap(df, 'label', 15)\n",
    "\n",
    "# todo excluir multicolinearidade?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkowRRLC-eJm"
   },
   "source": [
    "Podemos verificar que as features com maior correlação com o target são URLSimilarityIndex (0.86), HasSocialNet (0.78), HasCopyrightInfo (0.74), e HasDescription (0.69). URLTitleMatchScore e DomainTitleMatchScore têm uma forte correlação (0.96), podendo estar fornecendo informações semelhantes sobre o conteúdo da URL. Já CharContinuationRate (0.09) e HasTitle (0.16) tem as menores correlações com o target.\n",
    "\n",
    "Será utilizado o SelectKBest para filtrar as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5whl1sI-kcl"
   },
   "source": [
    "### Pipeline de Pré-processamento, Modelagem e Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyGpS6n__3XL"
   },
   "source": [
    "Optei por utilizar a validação cruzada porque, embora o dataset tenha uma quantidade razoável de observações, será necessário testar diferentes modelos e otimizar hiperparâmetros. Além disso, nos primeiros testes identifiquei sinais de overfitting, e a validação cruzada é uma técnica que permite avaliar o desempenho do modelo de forma mais confiável, ajudando a detectar e mitigar problemas de generalização.\n",
    "\n",
    "Como foi verificado um pequeno desbalanceamento, será utilizado o Smote para oversampling da classe minoritária.\n",
    "\n",
    "Realizei o split dos dados em treino, teste e validação. O conjunto de validação será usada na validação cruzada e otimização, enquanto o teste será para verificar o modelo final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuQWcKsNY6aG"
   },
   "source": [
    "Primeiramente, serão criados os métodos utilizados no pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djLKhrAX6AOH"
   },
   "source": [
    "## Definição do métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1734058700201,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "bJk2AklaNEqV"
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, random_state):\n",
    "    X = df.drop(columns=['label'])\n",
    "    y = df['label']\n",
    "\n",
    "    # Divisão inicial em treino/teste\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=random_state, stratify=y)\n",
    "\n",
    "    # Divisão treino/validação a partir do conjunto de treino completo\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=0.2, random_state=random_state, stratify=y_train_full)\n",
    "\n",
    "    # Balanceamento\n",
    "    smote = SMOTE(random_state=random_state)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    print(\"Distribuição das classes após SMOTE:\\n\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    return X_train_resampled, X_val, X_test, y_train_resampled, y_val, y_test\n",
    "\n",
    "\n",
    "def plot_learning_curve(models, X_train_split, y_train_split):\n",
    "    for name, pipeline in models.items():\n",
    "        train_sizes, train_scores, val_scores = learning_curve(\n",
    "            pipeline, X_train_split, y_train_split,\n",
    "            train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "            scoring='accuracy',\n",
    "            cv=StratifiedKFold(n_splits=5), #None,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        val_mean = np.mean(val_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(train_sizes, train_mean, label='Acurácia de Treinamento', color='blue')\n",
    "        plt.plot(train_sizes, val_mean, label='Acurácia de Validação', color='green')\n",
    "        plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.1)\n",
    "        plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='green', alpha=0.1)\n",
    "\n",
    "        plt.title(f\"Curva de Aprendizado: {name}\")\n",
    "        plt.xlabel('Tamanho do Conjunto de Treinamento')\n",
    "        plt.ylabel('Acurácia')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def cross_validate_models(models, X_train_resampled, y_train_resampled, n_splits, random_state):\n",
    "    final_results = {}\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for name, pipeline in models.items():\n",
    "        fold_metrics = {\n",
    "            \"accuracy\": [],\n",
    "            \"precision\": [],\n",
    "            \"recall\": [],\n",
    "            \"f1_score\": [],\n",
    "            \"confusion_matrices\": [],\n",
    "            \"roc_curves\": []\n",
    "        }\n",
    "\n",
    "        for fold, (train_index, val_index) in enumerate(skf.split(X_train_resampled, y_train_resampled), start=1):\n",
    "            print(f\"Processando {name}  - fold {fold} de {n_splits}\")\n",
    "            X_train_fold = X_train_resampled.iloc[train_index]\n",
    "            y_train_fold = y_train_resampled.iloc[train_index]\n",
    "            X_val_fold = X_train_resampled.iloc[val_index]\n",
    "            y_val_fold = y_train_resampled.iloc[val_index]\n",
    "\n",
    "            pipeline.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = pipeline.predict(X_val_fold)\n",
    "\n",
    "\n",
    "            fold_metrics[\"accuracy\"].append(accuracy_score(y_val_fold, y_pred))\n",
    "            fold_metrics[\"precision\"].append(precision_score(y_val_fold, y_pred, average='weighted', zero_division=0))\n",
    "            fold_metrics[\"recall\"].append(recall_score(y_val_fold, y_pred, average='weighted', zero_division=0))\n",
    "            fold_metrics[\"f1_score\"].append(f1_score(y_val_fold, y_pred, average='weighted', zero_division=0))\n",
    "\n",
    "        final_results[name] = {\n",
    "            \"accuracy\": np.mean(fold_metrics[\"accuracy\"]),\n",
    "            \"precision\": np.mean(fold_metrics[\"precision\"]),\n",
    "            \"recall\": np.mean(fold_metrics[\"recall\"]),\n",
    "            \"f1_score\": np.mean(fold_metrics[\"f1_score\"]),\n",
    "        }\n",
    "\n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzQP2GmiZDsC"
   },
   "source": [
    "A seguir, definirei as variáveis para o SelectKBest, validação cruzada, random state, as variáveis resultantes do holdout e a divisão para a curva de aprendizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCbEiUv46IJo"
   },
   "source": [
    "## Definição de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1734058700201,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "kKx_tS10XFZy",
    "outputId": "43c2c611-a152-4f44-9f41-b7ad3e2240ff"
   },
   "outputs": [],
   "source": [
    "# Definição de variáveis\n",
    "random_state = 12\n",
    "n_splits = 10\n",
    "k_values = [5, 10, 15, 20]\n",
    "\n",
    "# Divisão dos dados\n",
    "X_train_resampled, X_val, X_test, y_train_resampled, y_val, y_test = prepare_data(df, random_state)\n",
    "\n",
    "# Divisão para curva de aprendizado\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_resampled, y_train_resampled, test_size=0.2, random_state=random_state, stratify=y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw93XwIW6Nvb"
   },
   "source": [
    "## Tratamento de Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN-FyUvxZ6Kv"
   },
   "source": [
    "Foram feitos tratamentos nos outliers como teste, principalmente para verificar overfitting, porém todas as técnicas pioraram os resultados obtidos nas curvas de aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1734058700201,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "2MwbgC2dYVyl"
   },
   "outputs": [],
   "source": [
    "# Testes - Tratamento de outliers\n",
    "\n",
    "# def iqr_transform(X):\n",
    "#     Q1 = np.percentile(X, 25, axis=0)\n",
    "#     Q3 = np.percentile(X, 75, axis=0)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "#     return np.clip(X, lower_bound, upper_bound)\n",
    "#boolean_columns = [col for col in df.columns if col not in continuous_columns]\n",
    "# def winsorize_data(X, limits=[0.05, 0.05]):\n",
    "#     return pd.DataFrame(winsorize(X, limits=limits, axis=0), columns=X.columns)\n",
    "# log_transformer = FunctionTransformer(np.log1p)\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         # ('winsorize', FunctionTransformer(lambda X: winsorize_data(X, limits=[0.05, 0.05])), continuous_columns),\n",
    "#         ('log_transform', log_transformer, continuous_columns)\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yD02YWS6gPI"
   },
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5_x3BJzaAzZ"
   },
   "source": [
    "A seguir, foi criado o pipeline dos modelos, padronização com o StandardScaler para igualar as escalas, o SelectKBest para selecionar as 15 melhores features e a instanciação dos modelos.\n",
    "\n",
    "Os hiperparâmetros dos modelos foram otimizados para evitar overfitting principalmente por meio de regularização e controle da complexidade do modelo. A regularização (como no caso de penalização L2 na regressão logística e o parâmetro C no SVM) ajuda a prevenir que o modelo se ajuste excessivamente aos dados de treinamento. A limitação da profundidade das árvores, como no Random Forest e XGBoost, e o ajuste de parâmetros como o número de vizinhos no KNN também contribuem para reduzir a complexidade e evitar que o modelo se ajuste de maneira excessiva a variações nos dados de treinamento. Além disso, a seleção de características relevantes com SelectKBest ajuda a melhorar a generalização dos modelos ao reduzir a dimensionalidade dos dados.\n",
    "\n",
    "Foram escolhidos os modeloos clássicos para problemas de classificação, porém poderiam ser usadas técnicas mais avançadas como ensembles e redes neurais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1734058700201,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "uNjx05zAYMSO"
   },
   "outputs": [],
   "source": [
    "# Modelos e pipelines\n",
    "models = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        #('preprocessor', preprocessor),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_selection', SelectKBest(score_func=f_classif, k=10)),\n",
    "        ('model', LogisticRegression(max_iter=200, penalty='l2', C=1.0, random_state=random_state))\n",
    "    ]),\n",
    "    \"K-Nearest Neighbors\": Pipeline([\n",
    "        #('preprocessor', preprocessor),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_selection', SelectKBest(score_func=f_classif, k=10)),\n",
    "        ('model', KNeighborsClassifier(n_neighbors=10, weights='uniform'))\n",
    "    ]),\n",
    "    \"Support Vector Machine\": Pipeline([\n",
    "        #('preprocessor', preprocessor),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_selection', SelectKBest(score_func=f_classif, k=10)),\n",
    "        ('model', SVC(kernel='linear', C=0.5, random_state=random_state)) # c... reduzir penalização por erros... tentando evitar overfitting\n",
    "    ]),\n",
    "    \"Random Forest\": Pipeline([\n",
    "        #('preprocessor', preprocessor),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_selection', SelectKBest(score_func=f_classif, k=10)),\n",
    "        ('model', RandomForestClassifier(max_depth=10, min_samples_split=5, min_samples_leaf=4, random_state=random_state))\n",
    "    ]),\n",
    "    \"XGBoost\": Pipeline([\n",
    "        #('preprocessor', preprocessor),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_selection', SelectKBest(score_func=f_classif, k=10)),\n",
    "        ('model', XGBClassifier(eval_metric='logloss', max_depth=5, learning_rate=0.1, random_state=random_state))\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmpJ0P9F6j_p"
   },
   "source": [
    "## Curvas de Aprendizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mThCfeNEdgk9"
   },
   "source": [
    "Como estava tendo resultados muito altos, implementei as curvas de aprendizado para verificar se não estava ocorrendo overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "7gWa80I2Xy4e",
    "outputId": "9140d8b5-46e3-48d7-a7d0-7aa54b06f73c"
   },
   "outputs": [],
   "source": [
    "# Plotagem da curva de aprendizado\n",
    "plot_learning_curve(models, X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-__1W5SS6pmX"
   },
   "source": [
    "## Validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25995,
     "status": "ok",
     "timestamp": 1734059504000,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "ilYlNUxrXc3z",
    "outputId": "6b556590-a3f9-4a12-8b52-edb35dd24d79"
   },
   "outputs": [],
   "source": [
    "# Validação cruzada\n",
    "results = cross_validate_models(models, X_train_resampled, y_train_resampled, n_splits, random_state)\n",
    "\n",
    "# Resultados Validação Cruzada\n",
    "for model, metrics in results.items():\n",
    "    print(f\"\\nModelo: {model}\")\n",
    "    print(f\"  Acurácia: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precisão: {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1-score: {metrics['f1_score']:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JSkbQQyBWmD"
   },
   "source": [
    "Todos os modelos apresentaram resultados extremamente altos. Realizei a validação cruzada e plotei as curvas de aprendizado e não identifiquei o overfitting. Pode ter ocorrido também vazamento de dados, ou algum problema relacionado aos outliers que não consegui identificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUEBe8Jk6seN"
   },
   "source": [
    "## Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6125,
     "status": "ok",
     "timestamp": 1734059510122,
     "user": {
      "displayName": "Juliana Ferreira",
      "userId": "12681251841458340477"
     },
     "user_tz": 180
    },
    "id": "bD206JszYv6q",
    "outputId": "88559771-3f9c-41d1-8f55-6609e0287882"
   },
   "outputs": [],
   "source": [
    "# Avaliação do modelo final no conjunto de teste\n",
    "final_model = models[\"XGBoost\"]\n",
    "final_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "y_test_prob = final_model.predict_proba(X_test)[:, 1]  # curva ROC\n",
    "\n",
    "print(\"\\nAvaliação final no conjunto de teste:\")\n",
    "print(f\"  Acurácia: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  Precisão: {precision_score(y_test, y_test_pred, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, y_test_pred, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"  F1-score: {f1_score(y_test, y_test_pred, average='weighted', zero_division=0):.4f}\")\n",
    "\n",
    "labels = [0, 1]\n",
    "\n",
    "# Matriz de Confusão\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm_test, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.title('\\nMatriz de Confusão no Conjunto de Teste')\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print('')\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Falsos Positivos')\n",
    "plt.ylabel('Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLqBSOaV6ue6"
   },
   "source": [
    "## Considerações Finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgQn6N4EH8bu"
   },
   "source": [
    "Foi escolhido o modelo XGBoost por ter apresentado boas métricas e uma boa curva de aprendizado sem overfitting, já que a diferença entre as métricas de treino e validação não foi muito grande, o que indica boa generalização."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPv2v5BkBnZfICiM2Rf5ZrQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
